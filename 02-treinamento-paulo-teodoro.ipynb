{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np  # <-- Adicionado para localizar os índices das classes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.pipeline import make_pipeline\nfrom lime.lime_text import LimeTextExplainer\nimport joblib\n\n# 1. Preparação e Limpeza\ntrain = pd.read_csv('train.csv')\n# Concatenando Título e Texto para não perder contexto\ntrain['total_content'] = train['title'].fillna('') + \" \" + train['text'].fillna('')\n\nX = train['total_content']\ny = train['label']\n\n# 2. Divisão Hold-out (80/20) com semente fixa para reprodutibilidade\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# 3. Vetorização com Bigramas\n# ATENÇÃO: Se o seu dataset for em português, troque 'english' por 'portuguese' ou None.\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=15000, stop_words='english')\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_val_tfidf = vectorizer.transform(X_val)\n\n# 4. Treinamento do Modelo (Corrigido com max_iter=1000)\nmodel = LogisticRegression(C=10, class_weight='balanced', max_iter=1000, random_state=42)\nmodel.fit(X_train_tfidf, y_train)\n\n# 5. Validação Interna e Métricas\ny_pred = model.predict(X_val_tfidf)\nprint(\"=== Matriz de Confusão ===\")\nprint(confusion_matrix(y_val, y_pred))\nprint(\"\\n=== Relatório de Classificação ===\")\nprint(classification_report(y_val, y_pred))\n\n# 6. Interpretabilidade (XAI) com LIME\n# Criamos um pipeline porque o LIME precisa do texto cru como entrada, e não o texto vetorizado\npipeline = make_pipeline(vectorizer, model)\n\n# CORREÇÃO: Identificando claramente que 0 = True (Real) e 1 = Fake\nexplainer = LimeTextExplainer(class_names=['True (0)', 'Fake (1)']) \n\n# Pegando a primeira ocorrência de cada classe corretamente na base de validação\nidx_true = np.where(y_val == 0)[0][0] # 0 é a notícia real (ex: Reuters)\nidx_fake = np.where(y_val == 1)[0][0] # 1 é a notícia falsa (ex: Sensacionalista)\n\n# Gerando e salvando a explicação da Notícia Real\nexp_true = explainer.explain_instance(X_val.iloc[idx_true], pipeline.predict_proba, num_features=10)\nexp_true.save_to_file('lime_true_explanation.html')\n\n# Gerando e salvando a explicação da Notícia Fake\nexp_fake = explainer.explain_instance(X_val.iloc[idx_fake], pipeline.predict_proba, num_features=10)\nexp_fake.save_to_file('lime_fake_explanation.html')\n\nprint(\"\\nRelatórios de Interpretabilidade LIME salvos como 'lime_true_explanation.html' e 'lime_fake_explanation.html'\")\n\n# 7. Salvando os Pesos e o Vetorizador (Engenharia de Software)\njoblib.dump(model, 'modelo_fake_news.pkl')\njoblib.dump(vectorizer, 'vectorizer.pkl')\nprint(\"Modelo e Vetorizador serializados com sucesso (.pkl)\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}