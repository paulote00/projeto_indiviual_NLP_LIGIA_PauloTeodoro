{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.pipeline import make_pipeline\nfrom lime.lime_text import LimeTextExplainer\nimport joblib\n\n# 1. Preparação e Limpeza\ntrain = pd.read_csv('train.csv')\n# Concatenando Título e Texto para não perder contexto\ntrain['total_content'] = train['title'].fillna('') + \" \" + train['text'].fillna('')\n\nX = train['total_content']\ny = train['label']\n\n# 2. Divisão Hold-out (80/20) com semente fixa para reprodutibilidade\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# 3. Vetorização com Bigramas\n# ATENÇÃO: Se o seu dataset for em português, troque 'english' por 'portuguese' ou None.\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=15000, stop_words='english')\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_val_tfidf = vectorizer.transform(X_val)\n\n# 4. Treinamento do Modelo (Corrigido com max_iter=1000)\nmodel = LogisticRegression(C=10, class_weight='balanced', max_iter=1000, random_state=42)\nmodel.fit(X_train_tfidf, y_train)\n\n# 5. Validação Interna e Métricas\ny_pred = model.predict(X_val_tfidf)\nprint(\"=== Matriz de Confusão ===\")\nprint(confusion_matrix(y_val, y_pred))\nprint(\"\\n=== Relatório de Classificação ===\")\nprint(classification_report(y_val, y_pred))\n\n# 6. Interpretabilidade (XAI) com LIME\n# Criamos um pipeline porque o LIME precisa do texto cru como entrada, e não o texto vetorizado\npipeline = make_pipeline(vectorizer, model)\nexplainer = LimeTextExplainer(class_names=['Real', 'Fake']) # Confirme se 0 é Real e 1 é Fake no seu dataset\n\n# Gerando explicação para a primeira notícia da base de validação\nidx_explicacao = 0\nexp = explainer.explain_instance(X_val.iloc[idx_explicacao], pipeline.predict_proba, num_features=10)\n\n# Salvando a explicação em HTML conforme descrito no README\nexp.save_to_file('lime_explicacao.html')\nprint(\"\\nRelatório de Interpretabilidade LIME salvo como 'lime_explicacao.html'\")\n\n# 7. Salvando os Pesos e o Vetorizador (Engenharia de Software)\njoblib.dump(model, 'modelo_fake_news.pkl')\njoblib.dump(vectorizer, 'vectorizer.pkl')\nprint(\"Modelo e Vetorizador serializados com sucesso (.pkl)\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}