{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":130314,"databundleVersionId":15656025}],"dockerImageVersionId":31286,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.pipeline import make_pipeline\nfrom lime.lime_text import LimeTextExplainer\nimport joblib\n\ndf_train = pd.read_csv('/kaggle/input/ligia-nlp/train.csv')\ndf_test = pd.read_csv('/kaggle/input/ligia-nlp/test.csv')\n\ndf_train['full_text'] = df_train['title'].fillna('') + \" \" + df_train['text'].fillna('')\ndf_test['full_text'] = df_test['title'].fillna('') + \" \" + df_test['text'].fillna('')\n\nX = df_train['full_text']\ny = df_train['label']\nX_test_final = df_test['full_text']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\npipeline = make_pipeline(\n    # Aumentamos para 15.000 palavras e ativamos a leitura de pares de palavras (ngram_range)\n    TfidfVectorizer(max_features=15000, stop_words='english', ngram_range=(1, 2)),\n    \n    # Adicionamos C=10 para otimizar os pesos e max_iter=1000 para garantir que ele treine até o fim\n    LogisticRegression(C=10, class_weight='balanced', random_state=42, max_iter=1000)\n)\n\npipeline.fit(X_train, y_train)\n\ny_pred_val = pipeline.predict(X_val)\nf1 = f1_score(y_val, y_pred_val, average='macro')\nconf_matrix = confusion_matrix(y_val, y_pred_val)\n\nprint(f\"F1-Score (Macro): {f1:.4f}\")\nprint(\"Matriz de Confusão:\\n\", conf_matrix)\n\nexplainer = LimeTextExplainer(class_names=['Fake (0)', 'True (1)'])\n\nidx_fake = np.where(y_val == 0)[0][0]\nidx_true = np.where(y_val == 1)[0][0]\n\nexp_fake = explainer.explain_instance(X_val.iloc[idx_fake], pipeline.predict_proba, num_features=10)\nexp_fake.save_to_file('lime_fake_explanation.html')\n\nexp_true = explainer.explain_instance(X_val.iloc[idx_true], pipeline.predict_proba, num_features=10)\nexp_true.save_to_file('lime_true_explanation.html')\n\ny_test_pred = pipeline.predict(X_test_final)\nsubmission = pd.DataFrame({'id': df_test['id'], 'target': y_test_pred})\nsubmission.to_csv('submission.csv', index=False)\n\n# --- SALVANDO OS ARTEFATOS ---\n# 1. Salva o pipeline completo (Vetorizador + Modelo)\njoblib.dump(pipeline, 'modelo_fake_news.pkl')\n\n# 2. Extrai APENAS o vetorizador de dentro do pipeline e salva separadamente\nvetorizador_extraido = pipeline.named_steps['tfidfvectorizer']\njoblib.dump(vetorizador_extraido, 'vectorizer.pkl')\n\n# --- COMENTÁRIOS DA EXECUÇÃO ---\n# pd.read_csv: Carrega os arquivos usando os caminhos exatos mapeados na nuvem do Kaggle.\n# df_train['full_text']: Mescla o título e o corpo da notícia para garantir o máximo de contexto ao algoritmo, tratando vazios com fillna('').\n# train_test_split: Separa 20% do volume para validação interna, mantendo a proporção exata de classes reais e falsas (stratify=y).\n# make_pipeline: Empacota a conversão de texto para matemática (TfidfVectorizer) e o treinamento do modelo (LogisticRegression) em um fluxo único.\n# f1_score / confusion_matrix: Extrai as métricas de performance exigidas para a etapa de Resultados do artigo.\n# LimeTextExplainer: Executa a análise de interpretabilidade (XAI), isolando quais palavras específicas ativaram a decisão do modelo.\n# exp_fake.save_to_file: Salva a análise visual do LIME em formato de página web (.html) para você capturar a tela.\n# submission.to_csv: Gera a tabela final padronizada para o Leaderboard da competição.\n# pipeline.named_steps: Acessa os componentes individuais do pipeline para serialização modular.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T19:44:27.011554Z","iopub.execute_input":"2026-02-21T19:44:27.011931Z","iopub.status.idle":"2026-02-21T19:45:02.381990Z","shell.execute_reply.started":"2026-02-21T19:44:27.011900Z","shell.execute_reply":"2026-02-21T19:45:02.380593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#apenas para nao errar as pastas no kaggle\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T17:48:49.073176Z","iopub.execute_input":"2026-02-20T17:48:49.074089Z","iopub.status.idle":"2026-02-20T17:48:49.081960Z","shell.execute_reply.started":"2026-02-20T17:48:49.074052Z","shell.execute_reply":"2026-02-20T17:48:49.081167Z"}},"outputs":[],"execution_count":null}]}